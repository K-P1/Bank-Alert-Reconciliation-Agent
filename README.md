# Bank Alert Reconciliation Agent (BARA)

A productionâ€‘oriented service that ingests bank alert emails, normalizes and enriches them, polls external transaction sources, and reconciles matches automatically via a configurable matching engine. It exposes a Telexâ€‘compatible JSONâ€‘RPC A2A endpoint with **natural language command support** and REST endpoints for worker management.

Status: Workâ€‘inâ€‘progress (Stages 1â€“6.5 complete, further stages planned). This README will evolve as new stages land.

## âœ¨ New in Stage 6.5: Natural Language Commands

BARA now understands plain English! Chat with it naturally through Telex:

- **"run reconciliation"** â†’ Triggers matching
- **"show summary"** â†’ Displays stats
- **"list unmatched"** â†’ Shows pending alerts
- **"get confidence report"** â†’ Performance metrics
- **"help"** â†’ Lists all commands

**Key Features:**

- ðŸš€ <100ms response time
- ðŸŽ¯ 98%+ recognition accuracy
- ðŸ”’ Zero LLM/API dependencies (regex-based)
- ðŸ”„ Full backward compatibility with structured JSON-RPC

No JSON structures to memorizeâ€”just type what you need! See [Stage 6.5 Completion](docs/Stage-6.5-Completion.md) and [Telex Workflow](docs/Telex-BARA-Workflow.md) for details.

## Table of contents

- Overview and goals
- Architecture at a glance
- Whatâ€™s implemented so far (by stage)
- Project layout and folder guide
- Getting started (uv) â€” Windows PowerShell
- Configuration
- Database, migrations, and seed data
- Running the app
- Background workers (poller, email fetcher)
- Testing, linting, and formatting
- Docker
- Bank mappings maintenance
- Roadmap and next steps
- License

## Overview and goals

The Bank Alert Reconciliation Agent ingests transactional signals (bank alert emails and APIâ€‘polled transactions), transforms them into a canonical form, and reconciles them using an extensible ruleâ€‘based matching engine. Primary goals:

- Highâ€‘quality normalization and enrichment tailored to the Nigerian banking ecosystem
- Efficient reconciliation with transparent scoring and metrics
- Operational readiness (logging, health checks, metrics, CI hooks)
- Clear extension points for new sources, rules, and data models

## Architecture at a glance

- Ingestion
  - IMAP email fetcher â†’ hybrid parser (rules + LLM + regex fallback)
  - Transaction poller â†’ external API clients (mock in dev)
- Normalization & enrichment
  - Amount, currency, timestamp, reference tokenization
  - Bank enrichment using centralized mappings
- Matching engine
  - Candidate retrieval + 7 weighted rules + tieâ€‘breaking
- Interfaces
  - JSONâ€‘RPC A2A endpoint (Telexâ€‘compatible)
  - REST endpoints for worker control and metrics
- Storage
  - Async SQLAlchemy, repositories, unitâ€‘ofâ€‘work, Alembic migrations
- Ops
  - Structured logging, health endpoints, configurable via env

See docs/Overview.md and docs/architecture.md for deeper design notes.

## Whatâ€™s implemented so far (by stage)

- Stage 1 â€” A2A API & infrastructure
  - JSONâ€‘RPC 2.0 endpoint (status implemented; others return Not Implemented)
  - Health endpoints, structured logging, configuration loader
- Stage 2 â€” Storage models & persistence layer
  - 5 models (email, transaction, match, log, config), repositories, UoW
  - Alembic migrations and data retention utilities
- Stage 3 â€” Transaction poller
  - 15â€‘minute cadence (configurable), retries, circuit breaker, metrics
  - Mock API client with realistic Nigerian data
- Stage 4 â€” Email fetcher & intelligent parser
  - IMAP connector, ruleâ€‘based filter, LLM assist (Groq), regex fallback
  - Background fetcher with deduplication and metrics
- Stage 5 â€” Normalization & enrichment
  - Amount, currency, timestamp, reference normalization
  - Bank enrichment via centralized mappings (118+ Nigerian banks/fintechs)
- Stage 6 â€” Matching engine
  - 7 weighted rules, fuzzy matching (rapidfuzz), composite keys, thresholds
  - Candidate retrieval strategies with fallback
- Stage 6.5 â€” Natural Language Command Interpreter âœ¨
  - Regex-based pattern matching (no LLM required)
  - 5 commands: help, reconcile, summary, list unmatched, confidence report
  - 50+ phrase variations recognized
  - <100ms response time, 98%+ accuracy
  - Full backward compatibility with structured calls
- Stage 7 â€” A2A Integration & Telex Workflow
  - JSONâ€‘RPC 2.0 endpoint with `status`, `message/send`, and `execute` methods
  - Synchronous reconciliation with rule-level scoring and batch summaries
  - Mock data refactoring (consolidated into single source of truth, 50% code reduction)
  - Enhanced mock data seeding with matching pairs strategy (70% match rate)
  - Configurable mock data via environment variables
  - Data clearing functionality with safety prompts

Refer to docs/Stage-1-Completion.md â€¦ docs/Stage-7-Completion.md for details.

## Project layout and folder guide

```
.
â”œâ”€ app/
â”‚  â”œâ”€ a2a/                # JSONâ€‘RPC A2A endpoint
â”‚  â”‚  â”œâ”€ router.py
â”‚  â”‚  â”œâ”€ command_interpreter.py  # Natural language pattern matching
â”‚  â”‚  â””â”€ command_handlers.py     # Command execution handlers
â”‚  â”œâ”€ core/               # Crossâ€‘cutting infrastructure
â”‚  â”‚  â”œâ”€ config.py        # Pydantic settings loader
â”‚  â”‚  â””â”€ logging.py       # structlog configuration & middleware
â”‚  â”œâ”€ db/                 # Persistence layer
â”‚  â”‚  â”œâ”€ base.py          # Async SQLAlchemy engine/session
â”‚  â”‚  â”œâ”€ init.py          # DB init/reset CLI
â”‚  â”‚  â”œâ”€ repository.py    # Base repository
â”‚  â”‚  â”œâ”€ unit_of_work.py  # Transaction/UoW
â”‚  â”‚  â”œâ”€ retention.py     # Cleanup and retention policies
â”‚  â”‚  â”œâ”€ seed_mock.py     # Dynamic mock data seeding (dev/demo)
â”‚  â”‚  â”œâ”€ models/          # ORM models (email, transaction, match, log, config)
â”‚  â”‚  â”œâ”€ repositories/    # Specialized repositories
â”‚  â”‚  â””â”€ migrations/      # Alembic env & versions
â”‚  â”œâ”€ emails/             # Email ingestion & parsing
â”‚  â”‚  â”œâ”€ imap_connector.py
â”‚  â”‚  â”œâ”€ filter.py
â”‚  â”‚  â”œâ”€ llm_client.py
â”‚  â”‚  â”œâ”€ regex_extractor.py
â”‚  â”‚  â”œâ”€ parser.py
â”‚  â”‚  â”œâ”€ fetcher.py
â”‚  â”‚  â”œâ”€ metrics.py
â”‚  â”‚  â””â”€ router.py        # REST endpoints
â”‚  â”œâ”€ normalization/      # Canonicalization & enrichment
â”‚  â”‚  â”œâ”€ models.py
â”‚  â”‚  â”œâ”€ banks.py         # Central Nigerian bank/fintech mappings (aliases/domains)
â”‚  â”‚  â””â”€ normalizer.py
â”‚  â”œâ”€ matching/           # Matching engine
â”‚  â”‚  â”œâ”€ config.py
â”‚  â”‚  â”œâ”€ models.py
â”‚  â”‚  â”œâ”€ fuzzy.py
â”‚  â”‚  â”œâ”€ retrieval.py
â”‚  â”‚  â”œâ”€ rules.py
â”‚  â”‚  â”œâ”€ scorer.py
â”‚  â”‚  â””â”€ engine.py
â”‚  â”œâ”€ testing/            # Shared mock data templates
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â””â”€ mock_data_templates.py  # Single source of truth for mock data patterns
â”‚  â””â”€ transactions/       # Poller & API clients
â”‚     â”œâ”€ clients/
â”‚     â”‚  â”œâ”€ base.py
â”‚     â”‚  â””â”€ mock_client.py
â”‚     â”œâ”€ config.py
â”‚     â”œâ”€ metrics.py
â”‚     â”œâ”€ poller.py
â”‚     â””â”€ router.py        # REST endpoints
â”œâ”€ docker/
â”‚  â””â”€ Dockerfile          # Slim Python 3.13 image
â”œâ”€ docs/                  # Architecture, stages, and roadmap
â”œâ”€ tests/                 # Unit tests and fixtures
â”‚  â”œâ”€ seed_fixtures.py    # Load static test data from fixtures
â”‚  â”œâ”€ fixtures/           # Hardcoded test data (emails, transactions)
â”‚  â””â”€ test_*.py           # Test files
â”œâ”€ main.py                # Entrypoint (delegates to app/main.py)
â”œâ”€ app/main.py            # FastAPI app assembly & health
â”œâ”€ pyproject.toml         # Project & dependency metadata
â”œâ”€ run_server.bat         # Windows helper to start dev server
â”œâ”€ run_checks.bat         # Windows helper for lint/test (if configured)
â””â”€ alembic.ini            # Alembic config
```

Highlights:

- Centralized bank mappings live in `app/normalization/banks.py` (aliases + domains + categories)
- Mock data templates unified in `app/testing/mock_data_templates.py` (single source of truth)
- Two seeding options: `app/db/seed_mock.py` (dynamic, large, 70% match rate) and `tests/seed_fixtures.py` (static, small)
- Configurable mock data via `MOCK_EMAIL_COUNT` and `POLLER_BATCH_SIZE` environment variables
- Tests and documentation accompany each stage

## Getting started (uv) â€” Windows PowerShell

Prerequisites:

- Python 3.13+
- uv (package/dependency manager): https://docs.astral.sh/uv/
- A running database (PostgreSQL recommended for dev/prod; SQLite used in tests)

Install uv (if needed):

```powershell
# Scoop
scoop install uv
# or, pipx
pipx install uv
```

Create a virtual environment and install dependencies:

```powershell
uv venv
uv sync
```

Set up environment variables:

```powershell
# Copy and edit as needed (if .env.example is present)
Copy-Item .env.example .env
# Then open .env and fill values (see Configuration section below)
```

## Configuration

Configuration is managed by Pydantic Settings (`app/core/config.py`) and environment variables. Key variables (expand as needed):

- Core:
  - `ENV` (development|staging|production)
  - `DEBUG` (true|false)
  - `A2A_AGENT_NAME` (e.g., bankMatcher)
- Database:
  - `DATABASE_URL` (e.g., postgresql+asyncpg://user:pass@host:5432/db)
  - `TEST_DATABASE_URL` (e.g., sqlite+aiosqlite:///./test_bara_db.sqlite3)
- Email / IMAP:
  - `IMAP_HOST`, `IMAP_USER`, `IMAP_PASS`
  - Optional behavior: poll intervals, batch sizes (see `app/emails/config.py`)
- LLM (optional):
  - `LLM_PROVIDER` (e.g., groq)
  - `GROQ_API_KEY`, `GROQ_MODEL`
- Transactions Poller (see `app/transactions/config.py`):
  - Poll interval, batch size, retries, circuit breaker thresholds
- Mock Data (development/testing):
  - `MOCK_EMAIL_COUNT` (default: 10, range: 1-100) â€” Number of mock emails to generate
  - `POLLER_BATCH_SIZE` (default: 100, range: 1-1000) â€” Number of mock transactions to generate

Defaults exist for many options; missing secrets should be provided via `.env`.

## Database, migrations, and seed data

Initialize and migrate the database:

```powershell
# Show current version
uv run alembic current
# Upgrade to latest
uv run alembic upgrade head
# Create a new migration (after model changes)
uv run alembic revision --autogenerate -m "your message"
```

Optional: seed data for development/testing:

```powershell
# Dynamic mock data (large volumes, guaranteed 70% match rate)
uv run python -m app.db.seed_mock 50 40 72

# Clear existing data first, then seed (prompts for confirmation)
uv run python -m app.db.seed_mock 100 80 48 true

# Static test fixtures (small dataset, for unit tests)
uv run python -m tests.seed_fixtures
```

Reset (dangerous in production):

```powershell
uv run python -m app.db.init reset
```

## Running the app

Start the FastAPI server (dev hotâ€‘reload):

```powershell
# Helper script
./run_server.bat

# Or directly with uvicorn
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Health checks:

- GET `/` â†’ `{ "status": "ok" }`
- GET `/healthz` â†’ `{ "status": "ok", "env": "development|staging|production" }`

A2A JSONâ€‘RPC (Telexâ€‘compatible):

- POST `/a2a/agent/BARA`
- POST `/a2a/agent/bankMatcher`

**Supported methods:**

- `status` â€” Health & configuration metadata
- `message/send` â€” Synchronous reconciliation with batch processing
  - **Natural language**: "reconcile 50 emails", "show summary", "list unmatched"
  - **Structured params**: `limit`, `email_ids`, `rematch`, `summarize`
  - Returns: Detailed artifacts with rule-level scores and batch summaries
- `execute` â€” Async job submission (placeholder for future queue integration)

Example natural language request:

```json
{
  "jsonrpc": "2.0",
  "id": "req-001",
  "method": "message/send",
  "params": {
    "message": {
      "parts": [{ "text": "reconcile 50 emails" }]
    }
  }
}
```

Example structured request:

```json
{
  "jsonrpc": "2.0",
  "id": "req-002",
  "method": "message/send",
  "params": {
    "limit": 10,
    "summarize": true
  }
}
```

See `docs/Stage-6.5-Completion.md` and `docs/Telex-BARA-Workflow.md` for detailed specifications.

## Background workers (poller, email fetcher)

Transactions poller endpoints (`app/transactions/router.py`):

- GET `/transactions/poller/status`
- POST `/transactions/poller/start`
- POST `/transactions/poller/stop`
- POST `/transactions/poller/poll` (manual oneâ€‘off)

Email fetcher endpoints (`app/emails/router.py`):

- GET `/emails/fetcher/status`
- POST `/emails/fetcher/start`
- POST `/emails/fetcher/stop`
- POST `/emails/fetcher/fetch` (manual oneâ€‘off)

Both services collect inâ€‘memory run metrics accessible via their status endpoints. Autoâ€‘start can be configured via their respective configs.

## Testing, linting, and formatting

Run unit tests:

```powershell
uv run pytest -q
```

Formatting and linting (tools are declared in `pyproject.toml` dev group):

```powershell
# Format with Black
uv run black .
# Import sorting with isort
uv run isort .
# Lint with Flake8
uv run flake8 .
```

Optional type checking (mypy config present; install if desired):

```powershell
uv add --group dev mypy
uv run mypy .
```

## Docker

Build and run a container image:

```powershell
# Build
docker build -t bara:dev -f docker/Dockerfile .
# Run
docker run --rm -p 8000:8000 --env-file .env bara:dev
```

## Bank mappings maintenance

Bank/fintech/microfinance alias and domain mappings are centralized in:

- `app/normalization/banks.py` (export: `BANK_MAPPINGS`)

Guidelines:

- Use lowercase alias keys without punctuation (e.g., `gtb`, `gtbank`, `kuda`)
- Provide a concise `code`, canonical `name`, and known `domains`
- Tag `category` (commercial | non_interest | fintech | microfinance)
- Add common aliases and verified email/web domains

## Roadmap and next steps

This project is being implemented in stages. **Completed: 1â€“7 (including 6.5)** â€” A2A integration, natural language interface, matching engine, and mock data infrastructure. Coming up:

- Stage 8: Pagination, advanced filtering, and query optimization
- Stage 9: Background job queue & async execution for `execute` method
- Authentication & rate limiting for agent endpoints
- Webhook callback delivery and push notifications
- Rule tuning and adaptive thresholds
- Prometheus metrics export and alerts
- Additional sources (webhooks, MMS/USSD, etc.)
- Broader bank and wallet coverage as needed
- Natural language enhancements (fuzzy matching, typo tolerance, multi-turn context)

See `docs/Roadmap.md` for the highâ€‘level plan and perâ€‘stage docs for details.

## License

See `LICENSE` for licensing information.

---

Maintainers: contributions are welcome. Please open an issue to propose changes, or submit a PR following the coding conventions, with tests and documentation where appropriate.
